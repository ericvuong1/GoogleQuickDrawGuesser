{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import cv2\n",
    "\n",
    "def preProcessImageObsolete(image, cutoff=127, maxContours=5):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.uint8(np.ones(im.shape))\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea)\n",
    "    for ind, contour in enumerate(largest_contours[maxContours:]):\n",
    "        mask = cv2.drawContours(mask, [largest_contours[ind]], -1, 0, -1)\n",
    "        \n",
    "    filteredImage = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "    ## plt.imshow(filteredImage)\n",
    "    return filteredImage\n",
    "\n",
    "def preprocess(image, cutoff=127, maxContours=5):\n",
    "    image = np.uint8(image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image,connectivity = 4)\n",
    "    sizes = stats[:,-1]\n",
    "    max_label = 5\n",
    "    max_size = sizes[1]\n",
    "    for i in range(1,nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "    img = np.zeros(output.shape)\n",
    "    img[output == max_label] = 255\n",
    "    return img\n",
    "\n",
    "def preProcessImage(image, cutoff=127, maxContours=10):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rect = cv2.minAreaRect(contours[0])\n",
    "    im = crop_minAreaRect(im, rect)\n",
    "    mask = np.zeros(im.shape, np.uint8)\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for ind, contour in enumerate(largest_contours[:5]):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        mask[y:y+h, x:x+w] = 255    \n",
    "    filteredImage = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "    #plt.imshow(filteredImage)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(thresh)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(mask)\n",
    "    return filteredImage.reshape((image.shape))\n",
    "\n",
    "data = np.load(\"dataset/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 10s - loss: 4.1300 - acc: 0.0388 - val_loss: 3.7194 - val_acc: 0.0320\n",
      "Epoch 2/100\n",
      " - 9s - loss: 3.8035 - acc: 0.0388 - val_loss: 3.4531 - val_acc: 0.0350\n",
      "Epoch 3/100\n",
      " - 9s - loss: 3.6025 - acc: 0.0372 - val_loss: 3.4088 - val_acc: 0.0400\n",
      "Epoch 4/100\n",
      " - 9s - loss: 3.5111 - acc: 0.0429 - val_loss: 3.4327 - val_acc: 0.0430\n",
      "Epoch 5/100\n",
      " - 9s - loss: 3.4660 - acc: 0.0399 - val_loss: 3.4248 - val_acc: 0.0300\n",
      "Epoch 6/100\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"dataset/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=32,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=40,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=40,\n",
    "                 kernel_size=(5, 5),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "\n",
    "plt.plot(train_history.history['acc'])\n",
    "plt.plot(train_history.history['val_acc'])\n",
    "epoch_num = len(train_history.epoch)\n",
    "final_epoch_train_acc = train_history.history['acc'][epoch_num - 1]\n",
    "final_epoch_validation_acc = train_history.history['val_acc'][epoch_num - 1]\n",
    "plt.text(epoch_num, final_epoch_train_acc, 'train = {:.3f}'.format(final_epoch_train_acc))\n",
    "plt.text(epoch_num, final_epoch_validation_acc-0.01, 'valid = {:.3f}'.format(final_epoch_validation_acc))\n",
    "plt.title('Train History')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmax=epoch_num+1)\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data_test = np.load(\"dataset/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-85b1d8e6dfe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# plt.imshow(data[n][1].reshape(100, 100))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def crop_minAreaRect(img, rect):\n",
    "\n",
    "    # rotate img\n",
    "    angle = rect[2]\n",
    "    rows,cols = img.shape[0], img.shape[1]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "    img_rot = cv2.warpAffine(img,M,(cols,rows))\n",
    "\n",
    "    # rotate bounding box\n",
    "    rect0 = (rect[0], rect[1], 0.0)\n",
    "    box = cv2.boxPoints(rect)\n",
    "    pts = np.int0(cv2.transform(np.array([box]), M))[0]    \n",
    "    pts[pts < 0] = 0\n",
    "\n",
    "    # crop\n",
    "    img_crop = img_rot[pts[1][1]:pts[0][1], \n",
    "                       pts[1][0]:pts[2][0]]\n",
    "\n",
    "    return img_crop\n",
    "\n",
    "n=900\n",
    "image = data[n][1].reshape(100,100)\n",
    "\n",
    "plt.imshow(preProcessImage(image))\n",
    "# plt.imshow(data[n][1].reshape(100, 100))\n",
    "print(type(image))\n",
    "y[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"dataset/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
