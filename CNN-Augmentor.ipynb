{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import sys\n",
    "stderr = sys.stderr\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "import keras\n",
    "sys.stderr = stderr\n",
    "from keras import *\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import plot_model\n",
    "from keras.models import load_model\n",
    "import cv2 as cv\n",
    "import Augmentor\n",
    "\n",
    "\n",
    "image_colmn = 40\n",
    "image_row  = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def imagify(origin_array, size):\n",
    "    #function to turn a 1d vector into a square matrix\n",
    "    #origin_aray -> any vector\n",
    "    #size -> the size of the matrix to create\n",
    "    new_array = np.zeros((size,size))\n",
    "    for i in range (0,size):\n",
    "        for j in range (0,size):\n",
    "            new_array[i][j] = origin_array[i*size+j]\n",
    "    return new_array\n",
    "\n",
    "def de_imagify(img, size):\n",
    "    #function to turn a square matrix into a vector\n",
    "    #img -> square matrix\n",
    "    #size -> the size of the square matrix\n",
    "    new_array = np.zeros((size ** 2))\n",
    "    for i in range(size):\n",
    "        for j in range(size):\n",
    "            new_array[i*size+j] = img[i][j]\n",
    "    return np.asarray(new_array)\n",
    "\n",
    "def crop_all_images(input_file_path, output_file_path):\n",
    "    #function to take all the images from the input_file_path, and crop them to a uniform size\n",
    "    #by default, all images are cropped and rescaled to 100,100\n",
    "    #the resulting images are saved into the output_file_path\n",
    "    #return: the size of the biggest cropped image, before rescaling\n",
    "    all_img = np.load(input_file_path, encoding='latin1')\n",
    "\n",
    "    #make an identical copy of the file, we will only modify the data of the images\n",
    "    cropped_img = all_img.copy()\n",
    "    #make a list to store the cropped images temporarily\n",
    "    cropped_list = []\n",
    "\n",
    "    #variables storing the size of the biggest image, used to resize all the samples\n",
    "    max_width = 0\n",
    "    max_height = 0\n",
    "    for i in tqdm(range(all_img.shape[0])):\n",
    "        #get the image in this row\n",
    "        img = imagify(all_img[i][1],100)\n",
    "        #make a copy that will remain unaltered\n",
    "        img_cpy = img.copy()\n",
    "        #blur the image\n",
    "        img = cv.GaussianBlur(img,(3,3),0)\n",
    "        # convert to grayscale\n",
    "        imgray = np.uint8(img * 255) \n",
    "        #convert to binary image\n",
    "        ret, thresh = cv.threshold(imgray, 20, 255, 0)\n",
    "        #get the contours in the image\n",
    "        im2, contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "        #convert to rgb to have 3 channels\n",
    "        im2 = cv.cvtColor(im2, cv.COLOR_GRAY2RGB)   \n",
    "        #now get the biggest contour from the image\n",
    "        maxArea = 0\n",
    "        maxIndex = 0\n",
    "        if len(contours) != 0:\n",
    "            for i in range(len(contours)):\n",
    "                if cv.contourArea(contours[i]) > maxArea:\n",
    "                    maxArea = cv.contourArea(contours[i])\n",
    "                    maxIndex = i\n",
    "        #get the coordinates of the rectangle surrounding the shape\n",
    "        a,b,c,d = cv.boundingRect(contours[maxIndex])\n",
    "        #draw the rectangle\n",
    "        #cv.rectangle(img,(a,b),(a+c,b+d),(255),1)\n",
    "        #crop the original image\n",
    "        crop = img_cpy[b:b+d, a:a+c]\n",
    "        temp_max = np.max([c,d])\n",
    "        crop = cv.resize(crop,(100,100))\n",
    "        cropped_img[i][1] = de_imagify(crop,100)\n",
    "        cropped_list.append(crop)\n",
    "        if (c > max_width):\n",
    "            max_width = c\n",
    "        if (d > max_height):\n",
    "            max_height = d\n",
    "\n",
    "    #get the max size, i.e. biggest value between width and height\n",
    "    max_size = np.max([max_height,max_width])\n",
    "    for i in tqdm(range(cropped_img.shape[0])):\n",
    "    #for i in tqdm(range(2)):\n",
    "        #resize the array\n",
    "        np.resize(cropped_img[i][1],(max_size ** 2))\n",
    "        #cropped_img[i][1].resize(max_size)\n",
    "        img = cropped_list[i]\n",
    "        #crop the image to the max size, as a square\n",
    "        crop = cv.resize(img,(max_size,max_size))\n",
    "        #cropped_img[i][1] = de_imagify(crop,max_size)\n",
    "        cropped_img[i][1] = de_imagify(crop,max_size)\n",
    "        #crop = cv.resize(crop,(100,100))\n",
    "\n",
    "\n",
    "    np.save(output_file_path, cropped_img)\n",
    "    return max_size\n",
    "\n",
    "def resize_all(input_file_path,output_file_path, current_size, size):\n",
    "    #function to resize all the images in a file\n",
    "    #takes the images in input_file_path and puts the resized ones in output_file_path\n",
    "    #current_size -> the current size of the square matrices representing the images\n",
    "    #size -> the wanted size of the square matrices\n",
    "    all_img = np.load(input_file_path, encoding='latin1')\n",
    "    print(all_img.shape[0])\n",
    "    all_copy = all_img.copy()\n",
    "    img_list = []\n",
    "    for i in tqdm(range(all_img.shape[0])):\n",
    "        img = imagify(all_img[i][1],current_size)\n",
    "        #resize the array\n",
    "        np.resize(all_img[i][1],(size ** 2))\n",
    "        resized_img = cv.resize(img,(size,size))\n",
    "        all_img[i][1] = de_imagify(resized_img,size)\n",
    "    np.save(output_file_path,all_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    class_label_name=[]\n",
    "    with open (train_label_filename,'r',) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "        for row in readCSV:\n",
    "            \n",
    "            class_label_name.append(row)\n",
    "    del class_label_name[0]\n",
    "    class_id_list = []\n",
    "    for i in range(len(class_name_list)):\n",
    "        class_id_list.append(i)\n",
    "        \n",
    "    hashmap = dict(zip(class_name_list,class_id_list))\n",
    "    class_label_vector=[]\n",
    "\n",
    "    for r in tqdm(class_label_name):\n",
    "        word = r[1]\n",
    "        if word in hashmap:\n",
    "            class_label_vector.append(hashmap[word])\n",
    "    images = np.load(read_train_filename,encoding='latin1')\n",
    "    train_data=[]\n",
    "    for i in tqdm(range(len(images))):\n",
    "            train_data.append([np.array((images[i][1]).reshape(1,image_colmn*image_row)),np.array(class_label_vector[i])])\n",
    "    np.save('train_data.npy',train_data)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_transform(image, alpha, sigma, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_.\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "       Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "       Proc. of the International Conference on Document Analysis and\n",
    "       Recognition, 2003.\n",
    "    \"\"\"\n",
    "    assert len(image.shape) == 2\n",
    "\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma, mode=\"constant\", cval=0) * alpha\n",
    "\n",
    "    x, y = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), indexing='ij')\n",
    "    indices = np.reshape(x + dx, (-1, 1)), np.reshape(y + dy, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_input(x):\n",
    "    return (x - mean_px) / std_px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('acc'))\n",
    "history = AccuracyHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:03<00:00, 158.46it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:50<00:00, 196.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [00:52<00:00, 189.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:09<00:00, 144.32it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:01<00:00, 162.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 10000/10000 [01:00<00:00, 165.13it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "read_train_filename = './all/train_images2.npy'\n",
    "\n",
    "train_label_filename = './all/train_labels.csv'\n",
    "train_data_filename = './train_data.npy'\n",
    "class_name_list =[\"sink\",\"pear\",\"moustache\",\"nose\",\"skateboard\",\"penguin\",\"peanut\",\"skull\",\"panda\",\"paintbrush\",\"nail\",\"apple\",\"rifle\",\"mug\",\"sailboat\",\"pineapple\",\"spoon\",\"rabbit\",\"shovel\",\"rollerskates\",\"screwdriver\",\"scorpion\",\"rhinoceros\",\"pool\",\"octagon\",\"pillow\",\"parrot\",\"squiggle\",\"mouth\",\"empty\",\"pencil\"]\n",
    "num_classes = 31\n",
    "size = crop_all_images('./all/train_images.npy','./all/train_images2.npy')#('comp-551-kaggle-master/all/train_images.npy','comp-551-kaggle-master/all/train_images2.npy')\n",
    "resize_all('./all/train_images2.npy','./all/train_images2.npy',size,image_colmn)\n",
    "#code example taking the images in test_images.npy, cropping them, then rescaling them\n",
    "size = crop_all_images('./all/test_images.npy','./all/test_images2.npy')\n",
    "resize_all('./all/test_images2.npy','./all/test_images2.npy',size,image_colmn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 1671237.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 73452.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#checking processed data is exist.\n",
    "read_train_filename = './all/train_images2.npy'\n",
    "if (os.path.isfile(train_data_filename)==False):\n",
    "    train_data = create_train_data()\n",
    "        \n",
    "else:\n",
    "    print(\"file already exist\")\n",
    "    train_data = np.load(train_data_filename,encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 64273.92it/s]\n"
     ]
    }
   ],
   "source": [
    "read_test_filename = './all/test_images2.npy'\n",
    "\n",
    "test_data_filename = './test_data.npy'\n",
    "\n",
    "if (os.path.isfile(test_data_filename)==False):\n",
    "    images = np.load(read_test_filename,encoding='latin1')\n",
    "    predict_data=[]\n",
    "    for i in tqdm(range(len(images))):\n",
    "            predict_data.append([np.array((images[i][1])).reshape(1,image_colmn*image_row)])\n",
    "    np.save('test_data.npy',predict_data)\n",
    "    \n",
    "else:\n",
    "    print(\"file already exist\")\n",
    "    predict_data = np.load(test_data_filename,encoding='latin1')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(predict_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 1\n",
      "\t0: Skew (skew_type=RANDOM magnitude=0.2 probability=1 )\n",
      "Images: 0\n",
      "Classes: 0\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "aug_epochs = 50\n",
    "test_size = 0.05\n",
    "#seed \n",
    "random_seed = 1\n",
    "learning_rate=0.001\n",
    "version =1\n",
    "batch_size=128\n",
    "epochs=40\n",
    "\n",
    "\n",
    "y_raw = [i[1] for i in train_data]\n",
    "#print(y_raw)\n",
    "#for y_e in y_raw:\n",
    "#    y.append(convert_y_to_vector(y_e))\n",
    "train_y=np.asarray(y_raw,dtype=float)\n",
    "\n",
    "#print(y)\n",
    "\n",
    "train_y = train_y.reshape((-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_x = np.array([i[0] for i in train_data])\n",
    "train_x = train_x.reshape((-1,image_colmn,image_row))\n",
    "input_shape = (image_colmn, image_row, 1)\n",
    "predict_x = np.array([i[0] for i in predict_data])\n",
    "\n",
    "predict_x =predict_x.reshape((-1,image_colmn,image_row,1))\n",
    "\n",
    "    ###############################################################################\n",
    "    # Perspective skew\n",
    "p = Augmentor.Pipeline()\n",
    "p.skew(probability=1, magnitude=0.2)\n",
    "p.status()\n",
    "#print(x_train.shape)\n",
    "g = p.keras_generator_from_array(train_x, train_y, batch_size=train_x.shape[0])\n",
    "skew_1, skew_y_1 = next(g)\n",
    "#print(skew_1.shape)\n",
    "skew_2, skew_y_2 = next(g)\n",
    "skew_1 = skew_1.reshape(train_x.shape)\n",
    "skew_2 = skew_2.reshape(train_x.shape)\n",
    "    ###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "distort_1 = np.zeros(shape=train_x.shape, dtype='float32')\n",
    "distort_2 = np.zeros(shape=train_x.shape, dtype='float32')\n",
    "distort_3 = np.zeros(shape=train_x.shape, dtype='float32')\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "        #print(i)\n",
    "        distort_1[i] = elastic_transform(image=train_x[i], alpha=36, sigma=10)\n",
    "        distort_2[i] = elastic_transform(image=train_x[i], alpha=36, sigma=8)\n",
    "        distort_3[i] = elastic_transform(image=train_x[i], alpha=36, sigma=6)\n",
    "train_x =   np.concatenate((train_x, distort_1, distort_2, distort_3, skew_1, skew_2), axis=0)\n",
    "train_y = np.concatenate((train_y, train_y, train_y, train_y, skew_y_1, skew_y_2), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape((-1,image_colmn,image_row,1))\n",
    "train_y = train_y.reshape((train_y.shape[0],))\n",
    "train_x = train_x.astype('float32')\n",
    "predict_x = predict_x.astype('float32')\n",
    "train_x /= 255\n",
    "predict_x /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 40, 40, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predict_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=test_size, random_state=111)\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://keras.io/getting-started/sequential-model-guide/\n",
    "model = Sequential([\n",
    "        Lambda(norm_input, input_shape=input_shape),\n",
    "\n",
    "        Conv2D(32, strides=(1, 1),kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        Conv2D(32, strides=(1, 1),kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2),strides=(1, 1)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(0.25),\n",
    "\n",
    "        # Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        # Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        # Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        # BatchNormalization(),\n",
    "        # MaxPooling2D(pool_size=(2, 2)),\n",
    "        # Dropout(0.25),\n",
    "\n",
    "        Flatten(),\n",
    "\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        # Dense(512, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        # Dropout(0.5),\n",
    "        # Dense(512, activation='relu'),\n",
    "        # BatchNormalization(),\n",
    "        # Dropout(0.5),\n",
    "        Dense(31, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adam(lr=learning_rate),\n",
    "                  metrics=['accuracy'])   #https://keras.io/models/sequential/\n",
    "original = sys.stdout\n",
    "sys.stdout = open('history_' + str(version) + '.txt', 'w')\n",
    "\n",
    "model.summary()#https://keras.io/models/about-keras-models/#about-keras-models\n",
    "#https://keras.io/models/sequential/\n",
    "history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        class_weight=class_weights,\n",
    "                        callbacks =[history])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1ee30de80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = ImageDataGenerator(rotation_range=15, width_shift_range=0.1, shear_range=0.3,\n",
    "                             height_shift_range=0.1, zoom_range=0.08)  # changed from 8, 0.08, 0.3, 0.08\n",
    "#https://keras.io/preprocessing/image/#imagedatagenerator-class\n",
    "\n",
    "\n",
    "batches = gen.flow(x_train, y_train, batch_size=batch_size)\n",
    "\n",
    "val_batches = gen.flow(x_test, y_test, batch_size=batch_size)\n",
    "\n",
    "model.fit_generator(batches, steps_per_epoch=x_train.shape[0] // batch_size, epochs=aug_epochs,\n",
    "                        validation_data=val_batches, validation_steps=x_test.shape[0] // batch_size,\n",
    "                        use_multiprocessing=False, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "json_name = \"model_\" + str(version) + \".json\"\n",
    "h5_name = \"model_\" + str(version) + \".h5\"\n",
    "with open(json_name, \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(h5_name)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = model.predict_classes(predict_x, batch_size=batch_size, verbose=0)\n",
    "with open ('submission.csv','w',) as csvfile: \n",
    "    csvfile.write('Id')\n",
    "    csvfile.write(\",\")\n",
    "    csvfile.write('Category')\n",
    "    csvfile.write('\\n')\n",
    "    for i in range(len(predict_result)):\n",
    "            csvfile.write('%d'%i)\n",
    "            csvfile.write(\",\")\n",
    "            csvfile.write(class_name_list[predict_result[i]])\n",
    "            csvfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6b16d4610e32>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m11\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'History' object has no attribute 'acc'"
     ]
    }
   ],
   "source": [
    "plt.plot(range(1,11), history.acc)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
