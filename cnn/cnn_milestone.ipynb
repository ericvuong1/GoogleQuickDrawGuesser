{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      " - 10s - loss: 2.6068 - acc: 0.2649 - val_loss: 1.7400 - val_acc: 0.4980\n",
      "Epoch 2/37\n",
      " - 9s - loss: 1.7892 - acc: 0.4958 - val_loss: 1.2604 - val_acc: 0.6520\n",
      "Epoch 3/37\n",
      " - 8s - loss: 1.4891 - acc: 0.5797 - val_loss: 1.1972 - val_acc: 0.6700\n",
      "Epoch 4/37\n",
      " - 9s - loss: 1.2900 - acc: 0.6372 - val_loss: 1.0207 - val_acc: 0.7060\n",
      "Epoch 5/37\n",
      " - 8s - loss: 1.1694 - acc: 0.6628 - val_loss: 0.9669 - val_acc: 0.7120\n",
      "Epoch 6/37\n",
      " - 8s - loss: 1.0708 - acc: 0.6919 - val_loss: 0.8989 - val_acc: 0.7450\n",
      "Epoch 7/37\n",
      " - 8s - loss: 0.9914 - acc: 0.7172 - val_loss: 0.9476 - val_acc: 0.7430\n",
      "Epoch 8/37\n",
      " - 9s - loss: 0.9627 - acc: 0.7247 - val_loss: 0.8475 - val_acc: 0.7600\n",
      "Epoch 9/37\n",
      " - 9s - loss: 0.9110 - acc: 0.7420 - val_loss: 0.8154 - val_acc: 0.7680\n",
      "Epoch 10/37\n",
      " - 9s - loss: 0.8415 - acc: 0.7561 - val_loss: 0.8116 - val_acc: 0.7820\n",
      "Epoch 11/37\n",
      " - 8s - loss: 0.8024 - acc: 0.7634 - val_loss: 0.7593 - val_acc: 0.7860\n",
      "Epoch 12/37\n",
      " - 9s - loss: 0.7781 - acc: 0.7720 - val_loss: 0.8012 - val_acc: 0.7800\n",
      "Epoch 13/37\n",
      " - 9s - loss: 0.7498 - acc: 0.7781 - val_loss: 0.8098 - val_acc: 0.7850\n",
      "Epoch 14/37\n",
      " - 9s - loss: 0.7079 - acc: 0.7899 - val_loss: 0.7685 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 15/37\n",
      " - 8s - loss: 0.6231 - acc: 0.8126 - val_loss: 0.7540 - val_acc: 0.8030\n",
      "Epoch 16/37\n",
      " - 8s - loss: 0.5839 - acc: 0.8272 - val_loss: 0.7561 - val_acc: 0.8070\n",
      "Epoch 17/37\n",
      " - 8s - loss: 0.5499 - acc: 0.8327 - val_loss: 0.7601 - val_acc: 0.7980\n",
      "Epoch 18/37\n",
      " - 9s - loss: 0.5393 - acc: 0.8386 - val_loss: 0.7636 - val_acc: 0.7990\n",
      "Epoch 19/37\n",
      " - 9s - loss: 0.5246 - acc: 0.8361 - val_loss: 0.7905 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 20/37\n",
      " - 9s - loss: 0.4753 - acc: 0.8528 - val_loss: 0.7433 - val_acc: 0.8150\n",
      "Epoch 21/37\n",
      " - 8s - loss: 0.4503 - acc: 0.8666 - val_loss: 0.7249 - val_acc: 0.8110\n",
      "Epoch 22/37\n",
      " - 8s - loss: 0.4439 - acc: 0.8597 - val_loss: 0.7585 - val_acc: 0.8080\n",
      "Epoch 23/37\n",
      " - 8s - loss: 0.4235 - acc: 0.8681 - val_loss: 0.7550 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 24/37\n",
      " - 9s - loss: 0.3976 - acc: 0.8769 - val_loss: 0.7453 - val_acc: 0.8090\n",
      "Epoch 25/37\n",
      " - 9s - loss: 0.3945 - acc: 0.8763 - val_loss: 0.7535 - val_acc: 0.8170\n",
      "Epoch 26/37\n",
      " - 9s - loss: 0.3870 - acc: 0.8834 - val_loss: 0.7553 - val_acc: 0.8070\n",
      "Epoch 27/37\n",
      " - 8s - loss: 0.3828 - acc: 0.8819 - val_loss: 0.7616 - val_acc: 0.8120\n",
      "Epoch 28/37\n",
      " - 9s - loss: 0.3617 - acc: 0.8862 - val_loss: 0.7696 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 29/37\n",
      " - 9s - loss: 0.3586 - acc: 0.8898 - val_loss: 0.7578 - val_acc: 0.8170\n",
      "Epoch 30/37\n",
      " - 9s - loss: 0.3525 - acc: 0.8879 - val_loss: 0.7788 - val_acc: 0.8170\n",
      "Epoch 31/37\n",
      " - 9s - loss: 0.3568 - acc: 0.8886 - val_loss: 0.7714 - val_acc: 0.8150\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 32/37\n",
      " - 9s - loss: 0.3451 - acc: 0.8921 - val_loss: 0.7689 - val_acc: 0.8180\n",
      "Epoch 33/37\n",
      " - 9s - loss: 0.3377 - acc: 0.8934 - val_loss: 0.7740 - val_acc: 0.8210\n",
      "Epoch 34/37\n",
      " - 9s - loss: 0.3376 - acc: 0.8940 - val_loss: 0.7648 - val_acc: 0.8160\n",
      "Epoch 35/37\n",
      " - 9s - loss: 0.3386 - acc: 0.8927 - val_loss: 0.7612 - val_acc: 0.8160\n",
      "Epoch 36/37\n",
      " - 9s - loss: 0.3264 - acc: 0.8968 - val_loss: 0.7780 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 37/37\n",
      " - 9s - loss: 0.3260 - acc: 0.8976 - val_loss: 0.7734 - val_acc: 0.8190\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 37\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric Vuong\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:3122: MatplotlibDeprecationWarning: \n",
      "The `xmax` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `right` instead.\n",
      "  alternative='`right`', obj_type='argument')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "epoch_num = len(history.epoch)\n",
    "final_epoch_train_acc = history.history['acc'][epoch_num - 1]\n",
    "final_epoch_validation_acc = history.history['val_acc'][epoch_num - 1]\n",
    "plt.text(epoch_num, final_epoch_train_acc, 'train = {:.3f}'.format(final_epoch_train_acc))\n",
    "plt.text(epoch_num, final_epoch_validation_acc-0.01, 'valid = {:.3f}'.format(final_epoch_validation_acc))\n",
    "plt.title('Train History')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmax=epoch_num+1)\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      " - 8s - loss: 3.7875 - acc: 0.0579 - val_loss: 6.7417 - val_acc: 0.0420\n",
      "Epoch 2/37\n",
      " - 6s - loss: 3.3190 - acc: 0.0884 - val_loss: 3.5017 - val_acc: 0.0700\n",
      "Epoch 3/37\n",
      " - 6s - loss: 3.2008 - acc: 0.0911 - val_loss: 3.0078 - val_acc: 0.1190\n",
      "Epoch 4/37\n",
      " - 6s - loss: 2.8543 - acc: 0.1665 - val_loss: 2.7239 - val_acc: 0.2020\n",
      "Epoch 5/37\n",
      " - 6s - loss: 2.4871 - acc: 0.2665 - val_loss: 2.2990 - val_acc: 0.3210\n",
      "Epoch 6/37\n",
      " - 6s - loss: 2.1489 - acc: 0.3653 - val_loss: 2.0280 - val_acc: 0.3920\n",
      "Epoch 7/37\n",
      " - 6s - loss: 1.9243 - acc: 0.4364 - val_loss: 1.8474 - val_acc: 0.4570\n",
      "Epoch 8/37\n",
      " - 6s - loss: 1.7793 - acc: 0.4820 - val_loss: 1.6697 - val_acc: 0.5170\n",
      "Epoch 9/37\n",
      " - 7s - loss: 1.6640 - acc: 0.5191 - val_loss: 1.5765 - val_acc: 0.5290\n",
      "Epoch 10/37\n",
      " - 7s - loss: 1.5527 - acc: 0.5520 - val_loss: 1.5412 - val_acc: 0.5750\n",
      "Epoch 11/37\n",
      " - 6s - loss: 1.4740 - acc: 0.5741 - val_loss: 1.4686 - val_acc: 0.5800\n",
      "Epoch 12/37\n",
      " - 6s - loss: 1.3584 - acc: 0.6065 - val_loss: 1.3831 - val_acc: 0.6210\n",
      "Epoch 13/37\n",
      " - 6s - loss: 1.2866 - acc: 0.6283 - val_loss: 1.3145 - val_acc: 0.6380\n",
      "Epoch 14/37\n",
      " - 6s - loss: 1.2239 - acc: 0.6395 - val_loss: 1.2891 - val_acc: 0.6520\n",
      "Epoch 15/37\n",
      " - 6s - loss: 1.1493 - acc: 0.6598 - val_loss: 1.2719 - val_acc: 0.6600\n",
      "Epoch 16/37\n",
      " - 6s - loss: 1.1059 - acc: 0.6803 - val_loss: 1.2528 - val_acc: 0.6500\n",
      "Epoch 17/37\n",
      " - 6s - loss: 1.0775 - acc: 0.6856 - val_loss: 1.1964 - val_acc: 0.6780\n",
      "Epoch 18/37\n",
      " - 6s - loss: 1.0464 - acc: 0.6933 - val_loss: 1.1442 - val_acc: 0.6880\n",
      "Epoch 19/37\n",
      " - 6s - loss: 1.0153 - acc: 0.7008 - val_loss: 1.2792 - val_acc: 0.6520\n",
      "Epoch 20/37\n",
      " - 6s - loss: 0.9806 - acc: 0.7159 - val_loss: 1.1410 - val_acc: 0.6830\n",
      "Epoch 21/37\n",
      " - 6s - loss: 0.9363 - acc: 0.7284 - val_loss: 1.0838 - val_acc: 0.7130\n",
      "Epoch 22/37\n",
      " - 6s - loss: 0.9186 - acc: 0.7269 - val_loss: 1.0439 - val_acc: 0.7020\n",
      "Epoch 23/37\n",
      " - 6s - loss: 0.8891 - acc: 0.7411 - val_loss: 1.0705 - val_acc: 0.7180\n",
      "Epoch 24/37\n",
      " - 6s - loss: 0.8513 - acc: 0.7449 - val_loss: 1.2371 - val_acc: 0.6820\n",
      "Epoch 25/37\n",
      " - 6s - loss: 0.8335 - acc: 0.7559 - val_loss: 1.1803 - val_acc: 0.6790\n",
      "Epoch 26/37\n",
      " - 6s - loss: 0.8170 - acc: 0.7563 - val_loss: 1.1375 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 27/37\n",
      " - 6s - loss: 0.7289 - acc: 0.7820 - val_loss: 0.9511 - val_acc: 0.7340\n",
      "Epoch 28/37\n",
      " - 6s - loss: 0.6700 - acc: 0.8003 - val_loss: 0.9677 - val_acc: 0.7300\n",
      "Epoch 29/37\n",
      " - 6s - loss: 0.6405 - acc: 0.8035 - val_loss: 0.9856 - val_acc: 0.7360\n",
      "Epoch 30/37\n",
      " - 6s - loss: 0.6556 - acc: 0.8026 - val_loss: 1.0152 - val_acc: 0.7400\n",
      "Epoch 31/37\n",
      " - 6s - loss: 0.6157 - acc: 0.8131 - val_loss: 0.9975 - val_acc: 0.7380\n",
      "Epoch 32/37\n",
      " - 6s - loss: 0.6181 - acc: 0.8124 - val_loss: 1.0607 - val_acc: 0.7370\n",
      "Epoch 33/37\n",
      " - 6s - loss: 0.6056 - acc: 0.8146 - val_loss: 1.0026 - val_acc: 0.7460\n",
      "Epoch 34/37\n",
      " - 6s - loss: 0.6005 - acc: 0.8185 - val_loss: 1.0143 - val_acc: 0.7440\n",
      "Epoch 35/37\n",
      " - 6s - loss: 0.5647 - acc: 0.8252 - val_loss: 1.0215 - val_acc: 0.7310\n",
      "Epoch 36/37\n",
      " - 6s - loss: 0.5593 - acc: 0.8294 - val_loss: 1.0453 - val_acc: 0.7320\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 37/37\n",
      " - 6s - loss: 0.5220 - acc: 0.8350 - val_loss: 0.9849 - val_acc: 0.7480\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    image = preProcessImage(image)\n",
    "    image = rmEmpty(image)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 37\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    image = preProcessImage(image)\n",
    "    image = rmEmpty(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, cutoff=127, maxContours=5):\n",
    "    image = np.uint8(image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image,connectivity = 4)\n",
    "    sizes = stats[:,-1]\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2,nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "    img = np.zeros(output.shape)\n",
    "    img[output == max_label] = 255\n",
    "    return img\n",
    "\n",
    "def preProcessImage(image, cutoff=127, maxContours=10):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros(im.shape, np.uint8)\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for ind, contour in enumerate(largest_contours[:5]):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        mask[y:y+h, x:x+w] = 255    \n",
    "    filteredImage = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "    return filteredImage.reshape((image.shape))\n",
    "\n",
    "def rmEmpty(img):\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(img, connectivity=8)\n",
    "    sizes = stats[1:, -1]; nb_components = nb_components - 1\n",
    "    min_size = 50\n",
    "    img2 = np.zeros((output.shape))\n",
    "    for i in range(0, nb_components):\n",
    "        if sizes[i] >= min_size:\n",
    "            img2[output == i + 1] = 255\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/37\n",
      " - 8s - loss: 3.8259 - acc: 0.0555 - val_loss: 5.2294 - val_acc: 0.0500\n",
      "Epoch 2/37\n",
      " - 6s - loss: 3.3271 - acc: 0.0817 - val_loss: 3.6531 - val_acc: 0.0570\n",
      "Epoch 3/37\n",
      " - 6s - loss: 3.2067 - acc: 0.0942 - val_loss: 4.8093 - val_acc: 0.0540\n",
      "Epoch 4/37\n",
      " - 6s - loss: 3.0712 - acc: 0.1183 - val_loss: 3.3514 - val_acc: 0.1050\n",
      "Epoch 5/37\n",
      " - 6s - loss: 2.6790 - acc: 0.2046 - val_loss: 2.8103 - val_acc: 0.1680\n",
      "Epoch 6/37\n",
      " - 6s - loss: 2.3592 - acc: 0.2979 - val_loss: 2.1622 - val_acc: 0.3490\n",
      "Epoch 7/37\n",
      " - 6s - loss: 2.0736 - acc: 0.3848 - val_loss: 2.0721 - val_acc: 0.3800\n",
      "Epoch 8/37\n",
      " - 6s - loss: 1.8793 - acc: 0.4422 - val_loss: 1.7874 - val_acc: 0.4670\n",
      "Epoch 9/37\n",
      " - 7s - loss: 1.6925 - acc: 0.4959 - val_loss: 1.6909 - val_acc: 0.4850\n",
      "Epoch 10/37\n",
      " - 8s - loss: 1.5690 - acc: 0.5455 - val_loss: 1.4933 - val_acc: 0.5500\n",
      "Epoch 11/37\n",
      " - 6s - loss: 1.4770 - acc: 0.5674 - val_loss: 1.4112 - val_acc: 0.5880\n",
      "Epoch 12/37\n",
      " - 6s - loss: 1.3809 - acc: 0.5990 - val_loss: 1.3895 - val_acc: 0.6070\n",
      "Epoch 13/37\n",
      " - 6s - loss: 1.3189 - acc: 0.6144 - val_loss: 1.2926 - val_acc: 0.6170\n",
      "Epoch 14/37\n",
      " - 6s - loss: 1.2289 - acc: 0.6400 - val_loss: 1.3673 - val_acc: 0.5870\n",
      "Epoch 15/37\n",
      " - 7s - loss: 1.1969 - acc: 0.6515 - val_loss: 1.2984 - val_acc: 0.6430\n",
      "Epoch 16/37\n",
      " - 6s - loss: 1.1312 - acc: 0.6726 - val_loss: 1.2800 - val_acc: 0.6420\n",
      "Epoch 17/37\n",
      " - 6s - loss: 1.0949 - acc: 0.6796 - val_loss: 1.2646 - val_acc: 0.6590\n",
      "Epoch 18/37\n",
      " - 6s - loss: 1.0467 - acc: 0.6917 - val_loss: 1.2518 - val_acc: 0.6670\n",
      "Epoch 19/37\n",
      " - 6s - loss: 1.0383 - acc: 0.6951 - val_loss: 1.1922 - val_acc: 0.6900\n",
      "Epoch 20/37\n",
      " - 6s - loss: 1.0046 - acc: 0.7005 - val_loss: 1.2063 - val_acc: 0.6720\n",
      "Epoch 21/37\n",
      " - 6s - loss: 0.9680 - acc: 0.7169 - val_loss: 1.1771 - val_acc: 0.6770\n",
      "Epoch 22/37\n",
      " - 6s - loss: 0.9237 - acc: 0.7329 - val_loss: 1.0778 - val_acc: 0.7020\n",
      "Epoch 23/37\n",
      " - 6s - loss: 0.8866 - acc: 0.7402 - val_loss: 1.0996 - val_acc: 0.7010\n",
      "Epoch 24/37\n",
      " - 6s - loss: 0.8527 - acc: 0.7447 - val_loss: 1.0904 - val_acc: 0.7130\n",
      "Epoch 25/37\n",
      " - 6s - loss: 0.8225 - acc: 0.7548 - val_loss: 1.0002 - val_acc: 0.7240\n",
      "Epoch 26/37\n",
      " - 6s - loss: 0.8343 - acc: 0.7537 - val_loss: 1.0572 - val_acc: 0.7050\n",
      "Epoch 27/37\n",
      " - 6s - loss: 0.7877 - acc: 0.7609 - val_loss: 1.0670 - val_acc: 0.7060\n",
      "Epoch 28/37\n",
      " - 6s - loss: 0.7793 - acc: 0.7689 - val_loss: 1.0845 - val_acc: 0.7070\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 29/37\n",
      " - 6s - loss: 0.6568 - acc: 0.7989 - val_loss: 0.9895 - val_acc: 0.7480\n",
      "Epoch 30/37\n",
      " - 6s - loss: 0.6351 - acc: 0.8107 - val_loss: 0.9803 - val_acc: 0.7420\n",
      "Epoch 31/37\n",
      " - 6s - loss: 0.6115 - acc: 0.8162 - val_loss: 0.9916 - val_acc: 0.7480\n",
      "Epoch 32/37\n",
      " - 6s - loss: 0.5831 - acc: 0.8232 - val_loss: 0.9954 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 33/37\n",
      " - 6s - loss: 0.5494 - acc: 0.8335 - val_loss: 0.9615 - val_acc: 0.7490\n",
      "Epoch 34/37\n",
      " - 6s - loss: 0.5255 - acc: 0.8406 - val_loss: 0.9497 - val_acc: 0.7590\n",
      "Epoch 35/37\n",
      " - 6s - loss: 0.5116 - acc: 0.8411 - val_loss: 0.9910 - val_acc: 0.7460\n",
      "Epoch 36/37\n",
      " - 6s - loss: 0.5068 - acc: 0.8443 - val_loss: 0.9779 - val_acc: 0.7480\n",
      "Epoch 37/37\n",
      " - 6s - loss: 0.5065 - acc: 0.8441 - val_loss: 0.9377 - val_acc: 0.7610\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 37\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 7s - loss: 3.8427 - acc: 0.0557 - val_loss: 5.5204 - val_acc: 0.0440\n",
      "Epoch 2/15\n",
      " - 6s - loss: 3.3264 - acc: 0.0830 - val_loss: 3.4085 - val_acc: 0.0850\n",
      "Epoch 3/15\n",
      " - 6s - loss: 3.2062 - acc: 0.0968 - val_loss: 3.2053 - val_acc: 0.0990\n",
      "Epoch 4/15\n",
      " - 6s - loss: 2.9120 - acc: 0.1642 - val_loss: 2.6212 - val_acc: 0.2330\n",
      "Epoch 5/15\n",
      " - 6s - loss: 2.5344 - acc: 0.2477 - val_loss: 2.6262 - val_acc: 0.2360\n",
      "Epoch 6/15\n",
      " - 6s - loss: 2.2538 - acc: 0.3198 - val_loss: 2.4727 - val_acc: 0.2960\n",
      "Epoch 7/15\n",
      " - 6s - loss: 2.0462 - acc: 0.3901 - val_loss: 2.2860 - val_acc: 0.3570\n",
      "Epoch 8/15\n",
      " - 6s - loss: 1.8388 - acc: 0.4529 - val_loss: 1.8078 - val_acc: 0.4680\n",
      "Epoch 9/15\n",
      " - 6s - loss: 1.7047 - acc: 0.5028 - val_loss: 1.6772 - val_acc: 0.5050\n",
      "Epoch 10/15\n",
      " - 6s - loss: 1.5478 - acc: 0.5503 - val_loss: 1.6751 - val_acc: 0.5100\n",
      "Epoch 11/15\n",
      " - 6s - loss: 1.4533 - acc: 0.5760 - val_loss: 1.5045 - val_acc: 0.5740\n",
      "Epoch 12/15\n",
      " - 6s - loss: 1.3487 - acc: 0.6157 - val_loss: 1.3379 - val_acc: 0.6160\n",
      "Epoch 13/15\n",
      " - 6s - loss: 1.2759 - acc: 0.6293 - val_loss: 1.2873 - val_acc: 0.6430\n",
      "Epoch 14/15\n",
      " - 6s - loss: 1.2052 - acc: 0.6509 - val_loss: 1.1982 - val_acc: 0.6690\n",
      "Epoch 15/15\n",
      " - 6s - loss: 1.1588 - acc: 0.6636 - val_loss: 1.1872 - val_acc: 0.6650\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 40\n",
    "epochs = 15\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " - 8s - loss: 3.9393 - acc: 0.0421 - val_loss: 4.1351 - val_acc: 0.0350\n",
      "Epoch 2/30\n",
      " - 6s - loss: 3.4323 - acc: 0.0742 - val_loss: 3.2709 - val_acc: 0.0660\n",
      "Epoch 3/30\n",
      " - 6s - loss: 3.2665 - acc: 0.0887 - val_loss: 3.0933 - val_acc: 0.1010\n",
      "Epoch 4/30\n",
      " - 6s - loss: 3.1635 - acc: 0.0967 - val_loss: 3.0031 - val_acc: 0.1340\n",
      "Epoch 5/30\n",
      " - 6s - loss: 3.0689 - acc: 0.1141 - val_loss: 2.9350 - val_acc: 0.1220\n",
      "Epoch 6/30\n",
      " - 6s - loss: 3.0005 - acc: 0.1213 - val_loss: 2.9752 - val_acc: 0.1410\n",
      "Epoch 7/30\n",
      " - 6s - loss: 2.9103 - acc: 0.1456 - val_loss: 2.8058 - val_acc: 0.1640\n",
      "Epoch 8/30\n",
      " - 6s - loss: 2.6639 - acc: 0.2079 - val_loss: 2.7196 - val_acc: 0.1790\n",
      "Epoch 9/30\n",
      " - 6s - loss: 2.4740 - acc: 0.2614 - val_loss: 2.2975 - val_acc: 0.3070\n",
      "Epoch 10/30\n",
      " - 6s - loss: 2.3184 - acc: 0.3019 - val_loss: 2.1525 - val_acc: 0.3660\n",
      "Epoch 11/30\n",
      " - 6s - loss: 2.1642 - acc: 0.3556 - val_loss: 2.1129 - val_acc: 0.3450\n",
      "Epoch 12/30\n",
      " - 6s - loss: 2.0267 - acc: 0.3814 - val_loss: 1.9331 - val_acc: 0.4030\n",
      "Epoch 13/30\n",
      " - 6s - loss: 1.9107 - acc: 0.4337 - val_loss: 1.6701 - val_acc: 0.5050\n",
      "Epoch 14/30\n",
      " - 6s - loss: 1.8099 - acc: 0.4669 - val_loss: 1.6011 - val_acc: 0.5310\n",
      "Epoch 15/30\n",
      " - 6s - loss: 1.7177 - acc: 0.4981 - val_loss: 1.5927 - val_acc: 0.5060\n",
      "Epoch 16/30\n",
      " - 6s - loss: 1.6541 - acc: 0.5141 - val_loss: 1.5522 - val_acc: 0.5550\n",
      "Epoch 17/30\n",
      " - 6s - loss: 1.5636 - acc: 0.5449 - val_loss: 1.4659 - val_acc: 0.5930\n",
      "Epoch 18/30\n",
      " - 6s - loss: 1.4955 - acc: 0.5621 - val_loss: 1.3919 - val_acc: 0.6090\n",
      "Epoch 19/30\n",
      " - 6s - loss: 1.4262 - acc: 0.5851 - val_loss: 1.4196 - val_acc: 0.5870\n",
      "Epoch 20/30\n",
      " - 6s - loss: 1.3603 - acc: 0.6140 - val_loss: 1.3213 - val_acc: 0.6260\n",
      "Epoch 21/30\n",
      " - 6s - loss: 1.3492 - acc: 0.6161 - val_loss: 1.3393 - val_acc: 0.6120\n",
      "Epoch 22/30\n",
      " - 6s - loss: 1.2933 - acc: 0.6272 - val_loss: 1.1784 - val_acc: 0.6730\n",
      "Epoch 23/30\n",
      " - 6s - loss: 1.2390 - acc: 0.6446 - val_loss: 1.2150 - val_acc: 0.6620\n",
      "Epoch 24/30\n",
      " - 6s - loss: 1.2170 - acc: 0.6510 - val_loss: 1.5013 - val_acc: 0.6130\n",
      "Epoch 25/30\n",
      " - 6s - loss: 1.1871 - acc: 0.6627 - val_loss: 1.1645 - val_acc: 0.6780\n",
      "Epoch 26/30\n",
      " - 6s - loss: 1.1694 - acc: 0.6674 - val_loss: 1.1937 - val_acc: 0.6670\n",
      "Epoch 27/30\n",
      " - 6s - loss: 1.1434 - acc: 0.6724 - val_loss: 1.0611 - val_acc: 0.7090\n",
      "Epoch 28/30\n",
      " - 6s - loss: 1.0945 - acc: 0.6879 - val_loss: 1.1051 - val_acc: 0.6960\n",
      "Epoch 29/30\n",
      " - 6s - loss: 1.0638 - acc: 0.6972 - val_loss: 1.1640 - val_acc: 0.6810\n",
      "Epoch 30/30\n",
      " - 7s - loss: 1.0652 - acc: 0.6969 - val_loss: 1.1470 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=40,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 30\n",
    "epochs = 30\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "#     image = preprocess(image)\n",
    "#     image = preProcessImage(image)\n",
    "#     image = rmEmpty(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"all/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"all/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=20,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(4, 4),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=80,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #adam\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 37\n",
    "\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "data_test = np.load(\"all/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
