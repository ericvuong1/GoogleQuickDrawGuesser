{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 9s - loss: 3.2382 - acc: 0.1020 - val_loss: 3.2485 - val_acc: 0.1390\n",
      "Epoch 2/100\n",
      " - 7s - loss: 2.7326 - acc: 0.2057 - val_loss: 2.5533 - val_acc: 0.2200\n",
      "Epoch 3/100\n",
      " - 8s - loss: 2.4716 - acc: 0.2598 - val_loss: 2.3514 - val_acc: 0.3050\n",
      "Epoch 4/100\n",
      " - 7s - loss: 2.3558 - acc: 0.2997 - val_loss: 2.4110 - val_acc: 0.3010\n",
      "Epoch 5/100\n",
      " - 8s - loss: 2.2365 - acc: 0.3404 - val_loss: 2.2813 - val_acc: 0.3290\n",
      "Epoch 6/100\n",
      " - 7s - loss: 2.1523 - acc: 0.3561 - val_loss: 2.1495 - val_acc: 0.3570\n",
      "Epoch 7/100\n",
      " - 7s - loss: 2.0617 - acc: 0.3966 - val_loss: 2.0789 - val_acc: 0.3860\n",
      "Epoch 8/100\n",
      " - 7s - loss: 1.9851 - acc: 0.4187 - val_loss: 2.0585 - val_acc: 0.4170\n",
      "Epoch 9/100\n",
      " - 7s - loss: 1.9383 - acc: 0.4249 - val_loss: 2.0866 - val_acc: 0.4080\n",
      "Epoch 10/100\n",
      " - 7s - loss: 1.8735 - acc: 0.4486 - val_loss: 1.9230 - val_acc: 0.4410\n",
      "Epoch 11/100\n",
      " - 7s - loss: 1.8350 - acc: 0.4606 - val_loss: 1.9354 - val_acc: 0.4510\n",
      "Epoch 12/100\n",
      " - 7s - loss: 1.7903 - acc: 0.4746 - val_loss: 1.8366 - val_acc: 0.4750\n",
      "Epoch 13/100\n",
      " - 7s - loss: 1.7574 - acc: 0.4797 - val_loss: 1.8473 - val_acc: 0.4590\n",
      "Epoch 14/100\n",
      " - 7s - loss: 1.7142 - acc: 0.4919 - val_loss: 1.7413 - val_acc: 0.4850\n",
      "Epoch 15/100\n",
      " - 7s - loss: 1.6637 - acc: 0.5048 - val_loss: 1.7633 - val_acc: 0.4920\n",
      "Epoch 16/100\n",
      " - 7s - loss: 1.6375 - acc: 0.5122 - val_loss: 1.6647 - val_acc: 0.5180\n",
      "Epoch 17/100\n",
      " - 7s - loss: 1.6223 - acc: 0.5204 - val_loss: 1.7408 - val_acc: 0.4970\n",
      "Epoch 18/100\n",
      " - 7s - loss: 1.5781 - acc: 0.5307 - val_loss: 1.8019 - val_acc: 0.4950\n",
      "Epoch 19/100\n",
      " - 7s - loss: 1.5533 - acc: 0.5360 - val_loss: 1.7365 - val_acc: 0.5080\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 20/100\n",
      " - 7s - loss: 1.4740 - acc: 0.5582 - val_loss: 1.5969 - val_acc: 0.5320\n",
      "Epoch 21/100\n",
      " - 7s - loss: 1.4375 - acc: 0.5728 - val_loss: 1.5791 - val_acc: 0.5290\n",
      "Epoch 22/100\n",
      " - 7s - loss: 1.4460 - acc: 0.5688 - val_loss: 1.5837 - val_acc: 0.5440\n",
      "Epoch 23/100\n",
      " - 7s - loss: 1.4107 - acc: 0.5761 - val_loss: 1.5757 - val_acc: 0.5460\n",
      "Epoch 24/100\n",
      " - 7s - loss: 1.3841 - acc: 0.5916 - val_loss: 1.5280 - val_acc: 0.5630\n",
      "Epoch 25/100\n",
      " - 7s - loss: 1.3604 - acc: 0.5954 - val_loss: 1.5985 - val_acc: 0.5530\n",
      "Epoch 26/100\n",
      " - 7s - loss: 1.3604 - acc: 0.5962 - val_loss: 1.5612 - val_acc: 0.5660\n",
      "Epoch 27/100\n",
      " - 7s - loss: 1.3493 - acc: 0.5986 - val_loss: 1.5871 - val_acc: 0.5510\n",
      "Epoch 28/100\n",
      " - 7s - loss: 1.3457 - acc: 0.5988 - val_loss: 1.5506 - val_acc: 0.5640\n",
      "Epoch 29/100\n",
      " - 7s - loss: 1.3243 - acc: 0.6004 - val_loss: 1.4861 - val_acc: 0.5550\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 30/100\n",
      " - 7s - loss: 1.2856 - acc: 0.6149 - val_loss: 1.5038 - val_acc: 0.5600\n",
      "Epoch 31/100\n",
      " - 7s - loss: 1.2546 - acc: 0.6258 - val_loss: 1.4933 - val_acc: 0.5640\n",
      "Epoch 32/100\n",
      " - 7s - loss: 1.2557 - acc: 0.6253 - val_loss: 1.5002 - val_acc: 0.5770\n",
      "Epoch 33/100\n",
      " - 7s - loss: 1.2570 - acc: 0.6198 - val_loss: 1.4701 - val_acc: 0.5830\n",
      "Epoch 34/100\n",
      " - 7s - loss: 1.2362 - acc: 0.6282 - val_loss: 1.4871 - val_acc: 0.5790\n",
      "Epoch 35/100\n",
      " - 7s - loss: 1.2354 - acc: 0.6277 - val_loss: 1.4863 - val_acc: 0.5810\n",
      "Epoch 36/100\n",
      " - 7s - loss: 1.2352 - acc: 0.6270 - val_loss: 1.4899 - val_acc: 0.5750\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 37/100\n",
      " - 7s - loss: 1.2182 - acc: 0.6331 - val_loss: 1.4409 - val_acc: 0.5800\n",
      "Epoch 38/100\n",
      " - 7s - loss: 1.2078 - acc: 0.6381 - val_loss: 1.4574 - val_acc: 0.5820\n",
      "Epoch 39/100\n",
      " - 7s - loss: 1.1945 - acc: 0.6459 - val_loss: 1.4269 - val_acc: 0.5910\n",
      "Epoch 40/100\n",
      " - 7s - loss: 1.1963 - acc: 0.6364 - val_loss: 1.4149 - val_acc: 0.5930\n",
      "Epoch 41/100\n",
      " - 7s - loss: 1.1889 - acc: 0.6381 - val_loss: 1.4084 - val_acc: 0.5940\n",
      "Epoch 42/100\n",
      " - 8s - loss: 1.1692 - acc: 0.6491 - val_loss: 1.4678 - val_acc: 0.5650\n",
      "Epoch 43/100\n",
      " - 7s - loss: 1.1800 - acc: 0.6432 - val_loss: 1.4270 - val_acc: 0.5860\n",
      "Epoch 44/100\n",
      " - 7s - loss: 1.1646 - acc: 0.6473 - val_loss: 1.4343 - val_acc: 0.5800\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 45/100\n",
      " - 7s - loss: 1.1698 - acc: 0.6507 - val_loss: 1.4408 - val_acc: 0.5870\n",
      "Epoch 46/100\n",
      " - 7s - loss: 1.1339 - acc: 0.6542 - val_loss: 1.4241 - val_acc: 0.5900\n",
      "Epoch 47/100\n",
      " - 7s - loss: 1.1597 - acc: 0.6530 - val_loss: 1.4232 - val_acc: 0.5850\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 48/100\n",
      " - 7s - loss: 1.1517 - acc: 0.6551 - val_loss: 1.4095 - val_acc: 0.5850\n",
      "Epoch 49/100\n",
      " - 7s - loss: 1.1505 - acc: 0.6519 - val_loss: 1.4158 - val_acc: 0.5860\n",
      "Epoch 50/100\n",
      " - 7s - loss: 1.1573 - acc: 0.6531 - val_loss: 1.3970 - val_acc: 0.5920\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 51/100\n",
      " - 7s - loss: 1.1261 - acc: 0.6579 - val_loss: 1.4065 - val_acc: 0.5890\n",
      "Epoch 52/100\n",
      " - 7s - loss: 1.1238 - acc: 0.6611 - val_loss: 1.4159 - val_acc: 0.5900\n",
      "Epoch 53/100\n",
      " - 7s - loss: 1.1332 - acc: 0.6678 - val_loss: 1.4046 - val_acc: 0.5900\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 54/100\n",
      " - 7s - loss: 1.1219 - acc: 0.6668 - val_loss: 1.4082 - val_acc: 0.5930\n",
      "Epoch 55/100\n",
      " - 7s - loss: 1.1347 - acc: 0.6573 - val_loss: 1.4058 - val_acc: 0.5930\n",
      "Epoch 56/100\n",
      " - 7s - loss: 1.1465 - acc: 0.6566 - val_loss: 1.3975 - val_acc: 0.5930\n",
      "Epoch 57/100\n",
      " - 8s - loss: 1.1281 - acc: 0.6607 - val_loss: 1.4037 - val_acc: 0.5910\n",
      "Epoch 58/100\n",
      " - 8s - loss: 1.1181 - acc: 0.6617 - val_loss: 1.4080 - val_acc: 0.5920\n",
      "Epoch 59/100\n",
      " - 8s - loss: 1.1197 - acc: 0.6633 - val_loss: 1.4038 - val_acc: 0.5900\n",
      "Epoch 60/100\n",
      " - 8s - loss: 1.1334 - acc: 0.6540 - val_loss: 1.4016 - val_acc: 0.5890\n",
      "Epoch 61/100\n",
      " - 7s - loss: 1.1465 - acc: 0.6482 - val_loss: 1.4002 - val_acc: 0.5920\n",
      "Epoch 62/100\n",
      " - 8s - loss: 1.1317 - acc: 0.6590 - val_loss: 1.4018 - val_acc: 0.5900\n",
      "Epoch 63/100\n",
      " - 8s - loss: 1.1409 - acc: 0.6590 - val_loss: 1.4074 - val_acc: 0.5890\n",
      "Epoch 64/100\n",
      " - 7s - loss: 1.1296 - acc: 0.6603 - val_loss: 1.4050 - val_acc: 0.5890\n",
      "Epoch 65/100\n",
      " - 7s - loss: 1.1316 - acc: 0.6579 - val_loss: 1.4041 - val_acc: 0.5920\n",
      "Epoch 66/100\n",
      " - 7s - loss: 1.1085 - acc: 0.6676 - val_loss: 1.4016 - val_acc: 0.5910\n",
      "Epoch 67/100\n",
      " - 7s - loss: 1.1244 - acc: 0.6589 - val_loss: 1.4011 - val_acc: 0.5910\n",
      "Epoch 68/100\n",
      " - 8s - loss: 1.1296 - acc: 0.6519 - val_loss: 1.3994 - val_acc: 0.5900\n",
      "Epoch 69/100\n",
      " - 7s - loss: 1.1160 - acc: 0.6643 - val_loss: 1.3996 - val_acc: 0.5910\n",
      "Epoch 70/100\n",
      " - 7s - loss: 1.1204 - acc: 0.6588 - val_loss: 1.4043 - val_acc: 0.5920\n",
      "Epoch 71/100\n",
      " - 8s - loss: 1.1298 - acc: 0.6600 - val_loss: 1.3995 - val_acc: 0.5920\n",
      "Epoch 72/100\n",
      " - 7s - loss: 1.1308 - acc: 0.6589 - val_loss: 1.4011 - val_acc: 0.5940\n",
      "Epoch 73/100\n",
      " - 8s - loss: 1.1256 - acc: 0.6609 - val_loss: 1.4031 - val_acc: 0.5910\n",
      "Epoch 74/100\n",
      " - 8s - loss: 1.1267 - acc: 0.6606 - val_loss: 1.3993 - val_acc: 0.5910\n",
      "Epoch 75/100\n",
      " - 7s - loss: 1.1287 - acc: 0.6592 - val_loss: 1.3993 - val_acc: 0.5890\n",
      "Epoch 76/100\n",
      " - 8s - loss: 1.1201 - acc: 0.6640 - val_loss: 1.3961 - val_acc: 0.5920\n",
      "Epoch 77/100\n",
      " - 8s - loss: 1.1317 - acc: 0.6543 - val_loss: 1.4046 - val_acc: 0.5870\n",
      "Epoch 78/100\n",
      " - 7s - loss: 1.1243 - acc: 0.6658 - val_loss: 1.3933 - val_acc: 0.5930\n",
      "Epoch 79/100\n",
      " - 8s - loss: 1.1172 - acc: 0.6631 - val_loss: 1.3999 - val_acc: 0.5920\n",
      "Epoch 80/100\n",
      " - 7s - loss: 1.1177 - acc: 0.6616 - val_loss: 1.3952 - val_acc: 0.5950\n",
      "Epoch 81/100\n",
      " - 7s - loss: 1.1159 - acc: 0.6653 - val_loss: 1.3938 - val_acc: 0.5930\n",
      "Epoch 82/100\n",
      " - 7s - loss: 1.1251 - acc: 0.6642 - val_loss: 1.3943 - val_acc: 0.5940\n",
      "Epoch 83/100\n",
      " - 8s - loss: 1.1241 - acc: 0.6591 - val_loss: 1.3990 - val_acc: 0.5940\n",
      "Epoch 84/100\n",
      " - 7s - loss: 1.1298 - acc: 0.6593 - val_loss: 1.3935 - val_acc: 0.5920\n",
      "Epoch 85/100\n",
      " - 7s - loss: 1.1162 - acc: 0.6673 - val_loss: 1.3950 - val_acc: 0.5920\n",
      "Epoch 86/100\n",
      " - 7s - loss: 1.1111 - acc: 0.6632 - val_loss: 1.3945 - val_acc: 0.5910\n",
      "Epoch 87/100\n",
      " - 8s - loss: 1.1145 - acc: 0.6669 - val_loss: 1.3956 - val_acc: 0.5910\n",
      "Epoch 88/100\n",
      " - 7s - loss: 1.1105 - acc: 0.6688 - val_loss: 1.3954 - val_acc: 0.5920\n",
      "Epoch 89/100\n",
      " - 7s - loss: 1.1132 - acc: 0.6648 - val_loss: 1.3981 - val_acc: 0.5920\n",
      "Epoch 90/100\n",
      " - 7s - loss: 1.1188 - acc: 0.6629 - val_loss: 1.3937 - val_acc: 0.5960\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 7s - loss: 1.1210 - acc: 0.6604 - val_loss: 1.3999 - val_acc: 0.5910\n",
      "Epoch 92/100\n",
      " - 7s - loss: 1.1131 - acc: 0.6667 - val_loss: 1.3955 - val_acc: 0.5910\n",
      "Epoch 93/100\n",
      " - 7s - loss: 1.1182 - acc: 0.6612 - val_loss: 1.3915 - val_acc: 0.5930\n",
      "Epoch 94/100\n",
      " - 7s - loss: 1.1237 - acc: 0.6631 - val_loss: 1.3941 - val_acc: 0.5920\n",
      "Epoch 95/100\n",
      " - 7s - loss: 1.1271 - acc: 0.6533 - val_loss: 1.3946 - val_acc: 0.5960\n",
      "Epoch 96/100\n",
      " - 8s - loss: 1.1158 - acc: 0.6658 - val_loss: 1.3913 - val_acc: 0.5930\n",
      "Epoch 97/100\n",
      " - 7s - loss: 1.1166 - acc: 0.6621 - val_loss: 1.3916 - val_acc: 0.5980\n",
      "Epoch 98/100\n",
      " - 7s - loss: 1.1270 - acc: 0.6644 - val_loss: 1.4015 - val_acc: 0.5900\n",
      "Epoch 99/100\n",
      " - 7s - loss: 1.1035 - acc: 0.6653 - val_loss: 1.3926 - val_acc: 0.5910\n",
      "Epoch 100/100\n",
      " - 7s - loss: 1.1229 - acc: 0.6613 - val_loss: 1.3946 - val_acc: 0.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eric Vuong\\Anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\matplotlib\\axes\\_base.py:3122: MatplotlibDeprecationWarning: \n",
      "The `xmax` argument was deprecated in Matplotlib 3.0 and will be removed in 3.2. Use `right` instead.\n",
      "  alternative='`right`', obj_type='argument')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "import math\n",
    "\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "import cv2\n",
    "\n",
    "def preProcessImageObsolete(image, cutoff=127, maxContours=5):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.uint8(np.ones(im.shape))\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea)\n",
    "    for ind, contour in enumerate(largest_contours[maxContours:]):\n",
    "        mask = cv2.drawContours(mask, [largest_contours[ind]], -1, 0, -1)\n",
    "        \n",
    "    filteredImage = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "    ## plt.imshow(filteredImage)\n",
    "    return filteredImage\n",
    "\n",
    "def preprocess(image, cutoff=127, maxContours=5):\n",
    "    image = np.uint8(image)\n",
    "    nb_components, output, stats, centroids = cv2.connectedComponentsWithStats(image,connectivity = 4)\n",
    "    sizes = stats[:,-1]\n",
    "    max_label = 1\n",
    "    max_size = sizes[1]\n",
    "    for i in range(2,nb_components):\n",
    "        if sizes[i] > max_size:\n",
    "            max_label = i\n",
    "            max_size = sizes[i]\n",
    "    img = np.zeros(output.shape)\n",
    "    img[output == max_label] = 255\n",
    "    return img\n",
    "\n",
    "def preProcessImage(image, cutoff=127, maxContours=10):\n",
    "    image = np.uint8(image)\n",
    "    im = np.uint8(image)\n",
    "    red, thresh = cv2.threshold(im, cutoff, 255, 0)\n",
    "    im2, contours, hierarchy= cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    mask = np.zeros(im.shape, np.uint8)\n",
    "    largest_contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    for ind, contour in enumerate(largest_contours[:5]):\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        mask[y:y+h, x:x+w] = 255    \n",
    "    filteredImage = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "    #plt.imshow(filteredImage)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(thresh)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(mask)\n",
    "    return filteredImage.reshape((image.shape))\n",
    "\n",
    "data = np.load(\"dataset/train_images.npy\",encoding='bytes')\n",
    "\n",
    "x = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    x.append(image)\n",
    "\n",
    "x_pre = []\n",
    "for image in data:\n",
    "    image = image[1].reshape(100,100)\n",
    "    x_pre.append(image)\n",
    "\n",
    "\n",
    "\n",
    "labels = pd.read_csv(\"dataset/train_labels.csv\")\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    label = labels['Category'][i]\n",
    "    y.append(label)\n",
    "\n",
    "\n",
    "x_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size = 0.1, random_state=30)\n",
    "\n",
    "x_train_backup = x_train\n",
    "x_validation_backup = x_validation\n",
    "\n",
    "x_train = np.array(x_train).reshape(len(x_train), 100, 100, 1).astype('float32') / 255\n",
    "x_validation = np.array(x_validation).reshape(len(x_validation), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validation = encoder.fit_transform(y_validation)\n",
    "\n",
    "y_train_decoded = encoder.inverse_transform(y_train)\n",
    "y_validation_decoded = encoder.inverse_transform(y_train)\n",
    "\n",
    "\n",
    "##Setup CNN\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=36,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 input_shape=(100, 100, 1),\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=36,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(filters=36,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(Conv2D(filters=36,\n",
    "                 kernel_size=(3, 3),\n",
    "                 padding='same',\n",
    "                 activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(31, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "##Fit CNN model\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    zoom_range=0.1,  # Randomly zoom image\n",
    "    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr=0.00001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "train_history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                    epochs=epochs, validation_data=(x_validation, y_validation),\n",
    "                                    verbose=2, steps_per_epoch=x_train.shape[0] // batch_size\n",
    "                                    , callbacks=[learning_rate_reduction])\n",
    "\n",
    "\n",
    "plt.plot(train_history.history['acc'])\n",
    "plt.plot(train_history.history['val_acc'])\n",
    "epoch_num = len(train_history.epoch)\n",
    "final_epoch_train_acc = train_history.history['acc'][epoch_num - 1]\n",
    "final_epoch_validation_acc = train_history.history['val_acc'][epoch_num - 1]\n",
    "plt.text(epoch_num, final_epoch_train_acc, 'train = {:.3f}'.format(final_epoch_train_acc))\n",
    "plt.text(epoch_num, final_epoch_validation_acc-0.01, 'valid = {:.3f}'.format(final_epoch_validation_acc))\n",
    "plt.title('Train History')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xlim(xmax=epoch_num+1)\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "data_test = np.load(\"dataset/test_images.npy\",encoding='bytes')\n",
    "\n",
    "x_test = []\n",
    "for image in data_test:\n",
    "    image = image[1].reshape(100,100)\n",
    "    image = preprocess(image)\n",
    "    x_test.append(image)\n",
    "\n",
    "x_test = np.array(x_test).reshape(len(x_test), 100, 100, 1).astype('float32') / 255\n",
    "\n",
    "prediction = model.predict_classes(x_test)\n",
    "df = pd.DataFrame(prediction)\n",
    "df.index += 1\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['Category']\n",
    "df.to_csv('cnn.csv', header=True)\n",
    "\n",
    "word_class = []\n",
    "for i in range(len(df)):\n",
    "    c = encoder.classes_[df['Category'][i+1]]\n",
    "    word_class.append(c)\n",
    "\n",
    "word_class = np.array(word_class)\n",
    "word_class = pd.DataFrame(word_class)\n",
    "word_class.columns = ['Category']\n",
    "word_class.to_csv('cnn.csv', header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
